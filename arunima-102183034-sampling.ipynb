{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-02-19T12:02:57.028144Z","iopub.execute_input":"2023-02-19T12:02:57.028632Z","iopub.status.idle":"2023-02-19T12:02:57.035048Z","shell.execute_reply.started":"2023-02-19T12:02:57.028595Z","shell.execute_reply":"2023-02-19T12:02:57.033527Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/creditcard/Creditcard_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-02-19T12:03:01.571601Z","iopub.execute_input":"2023-02-19T12:03:01.572103Z","iopub.status.idle":"2023-02-19T12:03:01.591461Z","shell.execute_reply.started":"2023-02-19T12:03:01.572066Z","shell.execute_reply":"2023-02-19T12:03:01.590023Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T12:03:04.379345Z","iopub.execute_input":"2023-02-19T12:03:04.379865Z","iopub.status.idle":"2023-02-19T12:03:04.409706Z","shell.execute_reply.started":"2023-02-19T12:03:04.379827Z","shell.execute_reply":"2023-02-19T12:03:04.408365Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      1  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-19T12:03:07.366898Z","iopub.execute_input":"2023-02-19T12:03:07.367313Z","iopub.status.idle":"2023-02-19T12:03:07.375738Z","shell.execute_reply.started":"2023-02-19T12:03:07.367282Z","shell.execute_reply":"2023-02-19T12:03:07.374469Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"(772, 31)"},"metadata":{}}]},{"cell_type":"code","source":"sns.countplot(x=\"Class\", data=data)\n\nplt.xlabel('Class')\nplt.ylabel('Count')\nplt.title('Binary Class Distribution')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T12:03:09.782820Z","iopub.execute_input":"2023-02-19T12:03:09.783357Z","iopub.status.idle":"2023-02-19T12:03:10.015137Z","shell.execute_reply.started":"2023-02-19T12:03:09.783311Z","shell.execute_reply":"2023-02-19T12:03:10.013890Z"},"trusted":true},"execution_count":52,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/262839564.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcountplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Count'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Binary Class Distribution'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/_api/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 223\u001b[0;31m             f\"module {cls.__module__!r} has no attribute {name!r}\")\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'xlabel'"],"ename":"AttributeError","evalue":"module 'matplotlib' has no attribute 'xlabel'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"x = data.iloc[:,1:29]","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:51:03.513219Z","iopub.execute_input":"2023-02-19T11:51:03.513699Z","iopub.status.idle":"2023-02-19T11:51:03.521358Z","shell.execute_reply.started":"2023-02-19T11:51:03.513661Z","shell.execute_reply":"2023-02-19T11:51:03.519696Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"y = data.iloc[:,-1]","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:51:07.045993Z","iopub.execute_input":"2023-02-19T11:51:07.046383Z","iopub.status.idle":"2023-02-19T11:51:07.052241Z","shell.execute_reply.started":"2023-02-19T11:51:07.046334Z","shell.execute_reply":"2023-02-19T11:51:07.050965Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:51:09.274399Z","iopub.execute_input":"2023-02-19T11:51:09.274891Z","iopub.status.idle":"2023-02-19T11:51:09.286927Z","shell.execute_reply.started":"2023-02-19T11:51:09.274852Z","shell.execute_reply":"2023-02-19T11:51:09.285161Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_class_dist = y_train.value_counts(normalize=True)\ntest_class_dist = y_test.value_counts(normalize=True)\n\nprint(\"Training set class distribution:\\n\", train_class_dist)\nprint(\"Testing set class distribution:\\n\", test_class_dist)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:51:13.435769Z","iopub.execute_input":"2023-02-19T11:51:13.436198Z","iopub.status.idle":"2023-02-19T11:51:13.450230Z","shell.execute_reply.started":"2023-02-19T11:51:13.436164Z","shell.execute_reply":"2023-02-19T11:51:13.448819Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Training set class distribution:\n 0    0.988655\n1    0.011345\nName: Class, dtype: float64\nTesting set class distribution:\n 0    0.987097\n1    0.012903\nName: Class, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:51:16.760369Z","iopub.execute_input":"2023-02-19T11:51:16.760778Z","iopub.status.idle":"2023-02-19T11:51:16.768230Z","shell.execute_reply.started":"2023-02-19T11:51:16.760748Z","shell.execute_reply":"2023-02-19T11:51:16.766678Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"(617, 28)\n(617,)\n","output_type":"stream"}]},{"cell_type":"code","source":"#Random Oversampling\nfrom imblearn.over_sampling import RandomOverSampler\n\noversampler = RandomOverSampler(random_state=42)\nX_train_resampled, y_train_resampled = oversampler.fit_resample(X_train, y_train)\n\nsample_size = len(X_train_resampled) // 5\nsamples = []\nfor i in range(5):\n    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n    X_sample = X_train_resampled.iloc[sample_indices, :]\n    y_sample = y_train_resampled.iloc[sample_indices]\n    samples.append((X_sample, y_sample))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:51:22.446763Z","iopub.execute_input":"2023-02-19T11:51:22.447197Z","iopub.status.idle":"2023-02-19T11:51:22.470759Z","shell.execute_reply.started":"2023-02-19T11:51:22.447164Z","shell.execute_reply":"2023-02-19T11:51:22.469689Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\n\nmodels = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\nfor i, (X_sample, y_sample) in enumerate(samples):\n    print(f\"Sample {i+1}:\")\n    for model in models:\n        print(f\"\\t{model.__class__.__name__}:\")\n        model.fit(X_sample, y_sample)\n        y_pred = model.predict(X_test)\n        print(classification_report(y_test, y_pred, zero_division=1))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:53:13.987884Z","iopub.execute_input":"2023-02-19T11:53:13.988305Z","iopub.status.idle":"2023-02-19T11:53:18.467451Z","shell.execute_reply.started":"2023-02-19T11:53:13.988273Z","shell.execute_reply":"2023-02-19T11:53:18.466401Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Sample 1:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.33      0.50      0.40         2\n\n    accuracy                           0.98       155\n   macro avg       0.66      0.74      0.70       155\nweighted avg       0.98      0.98      0.98       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.50      0.50      0.50         2\n\n    accuracy                           0.99       155\n   macro avg       0.75      0.75      0.75       155\nweighted avg       0.99      0.99      0.99       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.50      0.50      0.50         2\n\n    accuracy                           0.99       155\n   macro avg       0.75      0.75      0.75       155\nweighted avg       0.99      0.99      0.99       155\n\nSample 2:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.99       153\n           1       0.25      0.50      0.33         2\n\n    accuracy                           0.97       155\n   macro avg       0.62      0.74      0.66       155\nweighted avg       0.98      0.97      0.98       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\nSample 3:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.98       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.97       155\n   macro avg       0.49      0.49      0.49       155\nweighted avg       0.97      0.97      0.97       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\nSample 4:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.33      0.50      0.40         2\n\n    accuracy                           0.98       155\n   macro avg       0.66      0.74      0.70       155\nweighted avg       0.98      0.98      0.98       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.50      0.50      0.50         2\n\n    accuracy                           0.99       155\n   macro avg       0.75      0.75      0.75       155\nweighted avg       0.99      0.99      0.99       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.33      0.50      0.40         2\n\n    accuracy                           0.98       155\n   macro avg       0.66      0.74      0.70       155\nweighted avg       0.98      0.98      0.98       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\nSample 5:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.17      0.50      0.25         2\n\n    accuracy                           0.96       155\n   macro avg       0.58      0.73      0.62       155\nweighted avg       0.98      0.96      0.97       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.50      0.50      0.50         2\n\n    accuracy                           0.99       155\n   macro avg       0.75      0.75      0.75       155\nweighted avg       0.99      0.99      0.99       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Random Undersampling\nfrom imblearn.under_sampling import RandomUnderSampler\n\nundersampler = RandomUnderSampler(random_state=42)\nX_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n\nsample_size = len(X_train) // 5\nsamples = []\nfor i in range(5):\n    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n    X_sample = X_train_resampled.iloc[sample_indices, :]\n    y_sample = y_train_resampled.iloc[sample_indices]\n    samples.append((X_sample, y_sample))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:54:00.678020Z","iopub.execute_input":"2023-02-19T11:54:00.678397Z","iopub.status.idle":"2023-02-19T11:54:00.705634Z","shell.execute_reply.started":"2023-02-19T11:54:00.678367Z","shell.execute_reply":"2023-02-19T11:54:00.703995Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\n\nmodels = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\nfor i, (X_sample, y_sample) in enumerate(samples):\n    print(f\"Sample {i+1}:\")\n    for model in models:\n        print(f\"\\t{model.__class__.__name__}:\")\n        model.fit(X_sample, y_sample)\n        y_pred = model.predict(X_test)\n        print(classification_report(y_test, y_pred, zero_division=1))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:54:48.149557Z","iopub.execute_input":"2023-02-19T11:54:48.150239Z","iopub.status.idle":"2023-02-19T11:54:51.575699Z","shell.execute_reply.started":"2023-02-19T11:54:48.150199Z","shell.execute_reply":"2023-02-19T11:54:51.574579Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Sample 1:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.58      0.73       153\n           1       0.02      0.50      0.03         2\n\n    accuracy                           0.58       155\n   macro avg       0.50      0.54      0.38       155\nweighted avg       0.98      0.58      0.72       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.46      0.63       153\n           1       0.01      0.50      0.02         2\n\n    accuracy                           0.46       155\n   macro avg       0.50      0.48      0.33       155\nweighted avg       0.97      0.46      0.62       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.54      0.70       153\n           1       0.01      0.50      0.03         2\n\n    accuracy                           0.54       155\n   macro avg       0.50      0.52      0.36       155\nweighted avg       0.98      0.54      0.69       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.51      0.67       153\n           1       0.01      0.50      0.03         2\n\n    accuracy                           0.51       155\n   macro avg       0.50      0.50      0.35       155\nweighted avg       0.97      0.51      0.66       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.59      0.74       153\n           1       0.02      0.50      0.03         2\n\n    accuracy                           0.59       155\n   macro avg       0.50      0.54      0.38       155\nweighted avg       0.98      0.59      0.73       155\n\nSample 2:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.48      0.65       153\n           1       0.01      0.50      0.02         2\n\n    accuracy                           0.48       155\n   macro avg       0.50      0.49      0.34       155\nweighted avg       0.97      0.48      0.64       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.53      0.69       153\n           1       0.01      0.50      0.03         2\n\n    accuracy                           0.53       155\n   macro avg       0.50      0.51      0.36       155\nweighted avg       0.98      0.53      0.68       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.56      0.72       153\n           1       0.01      0.50      0.03         2\n\n    accuracy                           0.56       155\n   macro avg       0.50      0.53      0.37       155\nweighted avg       0.98      0.56      0.71       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       1.00      0.37      0.54       153\n           1       0.02      1.00      0.04         2\n\n    accuracy                           0.37       155\n   macro avg       0.51      0.68      0.29       155\nweighted avg       0.99      0.37      0.53       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       1.00      0.37      0.54       153\n           1       0.02      1.00      0.04         2\n\n    accuracy                           0.37       155\n   macro avg       0.51      0.68      0.29       155\nweighted avg       0.99      0.37      0.53       155\n\nSample 3:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.49      0.66       153\n           1       0.01      0.50      0.02         2\n\n    accuracy                           0.49       155\n   macro avg       0.50      0.50      0.34       155\nweighted avg       0.97      0.49      0.65       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.44      0.61       153\n           1       0.01      0.50      0.02         2\n\n    accuracy                           0.44       155\n   macro avg       0.50      0.47      0.31       155\nweighted avg       0.97      0.44      0.60       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.61      0.76       153\n           1       0.02      0.50      0.03         2\n\n    accuracy                           0.61       155\n   macro avg       0.50      0.56      0.40       155\nweighted avg       0.98      0.61      0.75       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       1.00      0.37      0.54       153\n           1       0.02      1.00      0.04         2\n\n    accuracy                           0.37       155\n   macro avg       0.51      0.68      0.29       155\nweighted avg       0.99      0.37      0.53       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       1.00      0.37      0.54       153\n           1       0.02      1.00      0.04         2\n\n    accuracy                           0.37       155\n   macro avg       0.51      0.68      0.29       155\nweighted avg       0.99      0.37      0.53       155\n\nSample 4:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.49      0.66       153\n           1       0.01      0.50      0.02         2\n\n    accuracy                           0.49       155\n   macro avg       0.50      0.50      0.34       155\nweighted avg       0.97      0.49      0.65       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.48      0.65       153\n           1       0.01      0.50      0.02         2\n\n    accuracy                           0.48       155\n   macro avg       0.50      0.49      0.34       155\nweighted avg       0.97      0.48      0.64       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.55      0.71       153\n           1       0.01      0.50      0.03         2\n\n    accuracy                           0.55       155\n   macro avg       0.50      0.52      0.37       155\nweighted avg       0.98      0.55      0.70       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       1.00      0.35      0.51       153\n           1       0.02      1.00      0.04         2\n\n    accuracy                           0.35       155\n   macro avg       0.51      0.67      0.28       155\nweighted avg       0.99      0.35      0.51       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.98      0.42      0.59       153\n           1       0.01      0.50      0.02         2\n\n    accuracy                           0.43       155\n   macro avg       0.50      0.46      0.31       155\nweighted avg       0.97      0.43      0.59       155\n\nSample 5:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.49      0.66       153\n           1       0.01      0.50      0.02         2\n\n    accuracy                           0.49       155\n   macro avg       0.50      0.50      0.34       155\nweighted avg       0.97      0.49      0.65       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.52      0.68       153\n           1       0.01      0.50      0.03         2\n\n    accuracy                           0.52       155\n   macro avg       0.50      0.51      0.35       155\nweighted avg       0.97      0.52      0.67       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.60      0.75       153\n           1       0.02      0.50      0.03         2\n\n    accuracy                           0.60       155\n   macro avg       0.50      0.55      0.39       155\nweighted avg       0.98      0.60      0.74       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       1.00      0.37      0.54       153\n           1       0.02      1.00      0.04         2\n\n    accuracy                           0.37       155\n   macro avg       0.51      0.68      0.29       155\nweighted avg       0.99      0.37      0.53       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       1.00      0.37      0.54       153\n           1       0.02      1.00      0.04         2\n\n    accuracy                           0.37       155\n   macro avg       0.51      0.68      0.29       155\nweighted avg       0.99      0.37      0.53       155\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#Combined sampling(SMOTE)\nfrom imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\nsample_size = len(X_train) // 5\nsamples = []\nfor i in range(5):\n    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n    X_sample = X_train_resampled.iloc[sample_indices, :]\n    y_sample = y_train_resampled.iloc[sample_indices]\n    samples.append((X_sample, y_sample))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:55:19.766165Z","iopub.execute_input":"2023-02-19T11:55:19.766540Z","iopub.status.idle":"2023-02-19T11:55:19.791520Z","shell.execute_reply.started":"2023-02-19T11:55:19.766509Z","shell.execute_reply":"2023-02-19T11:55:19.790634Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\n\nmodels = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\nfor i, (X_sample, y_sample) in enumerate(samples):\n    print(f\"Sample {i+1}:\")\n    for model in models:\n        print(f\"\\t{model.__class__.__name__}:\")\n        model.fit(X_sample, y_sample)\n        y_pred = model.predict(X_test)\n        print(classification_report(y_test, y_pred, zero_division=1))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:55:56.504894Z","iopub.execute_input":"2023-02-19T11:55:56.505317Z","iopub.status.idle":"2023-02-19T11:56:00.536646Z","shell.execute_reply.started":"2023-02-19T11:55:56.505284Z","shell.execute_reply":"2023-02-19T11:56:00.535800Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Sample 1:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.96      0.98       153\n           1       0.14      0.50      0.22         2\n\n    accuracy                           0.95       155\n   macro avg       0.57      0.73      0.60       155\nweighted avg       0.98      0.95      0.97       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.50      0.50      0.50         2\n\n    accuracy                           0.99       155\n   macro avg       0.75      0.75      0.75       155\nweighted avg       0.99      0.99      0.99       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.97       153\n           1       0.10      0.50      0.17         2\n\n    accuracy                           0.94       155\n   macro avg       0.55      0.72      0.57       155\nweighted avg       0.98      0.94      0.96       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.90      0.94       153\n           1       0.06      0.50      0.11         2\n\n    accuracy                           0.89       155\n   macro avg       0.53      0.70      0.52       155\nweighted avg       0.98      0.89      0.93       155\n\nSample 2:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.97       153\n           1       0.10      0.50      0.17         2\n\n    accuracy                           0.94       155\n   macro avg       0.55      0.72      0.57       155\nweighted avg       0.98      0.94      0.96       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.50      0.50      0.50         2\n\n    accuracy                           0.99       155\n   macro avg       0.75      0.75      0.75       155\nweighted avg       0.99      0.99      0.99       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.80      0.88       153\n           1       0.03      0.50      0.06         2\n\n    accuracy                           0.79       155\n   macro avg       0.51      0.65      0.47       155\nweighted avg       0.98      0.79      0.87       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.93      0.96       153\n           1       0.08      0.50      0.14         2\n\n    accuracy                           0.92       155\n   macro avg       0.54      0.71      0.55       155\nweighted avg       0.98      0.92      0.95       155\n\nSample 3:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.93      0.96       153\n           1       0.09      0.50      0.15         2\n\n    accuracy                           0.93       155\n   macro avg       0.54      0.72      0.56       155\nweighted avg       0.98      0.93      0.95       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.93      0.96       153\n           1       0.09      0.50      0.15         2\n\n    accuracy                           0.93       155\n   macro avg       0.54      0.72      0.56       155\nweighted avg       0.98      0.93      0.95       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.97       153\n           1       0.10      0.50      0.17         2\n\n    accuracy                           0.94       155\n   macro avg       0.55      0.72      0.57       155\nweighted avg       0.98      0.94      0.96       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.92      0.95       153\n           1       0.07      0.50      0.12         2\n\n    accuracy                           0.91       155\n   macro avg       0.53      0.71      0.54       155\nweighted avg       0.98      0.91      0.94       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.91      0.95       153\n           1       0.07      0.50      0.12         2\n\n    accuracy                           0.90       155\n   macro avg       0.53      0.70      0.53       155\nweighted avg       0.98      0.90      0.94       155\n\nSample 4:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.88      0.93       153\n           1       0.05      0.50      0.09         2\n\n    accuracy                           0.87       155\n   macro avg       0.52      0.69      0.51       155\nweighted avg       0.98      0.87      0.92       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.96      0.98       153\n           1       0.14      0.50      0.22         2\n\n    accuracy                           0.95       155\n   macro avg       0.57      0.73      0.60       155\nweighted avg       0.98      0.95      0.97       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.95      0.97       153\n           1       0.12      0.50      0.20         2\n\n    accuracy                           0.95       155\n   macro avg       0.56      0.73      0.59       155\nweighted avg       0.98      0.95      0.96       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.93      0.96       153\n           1       0.09      0.50      0.15         2\n\n    accuracy                           0.93       155\n   macro avg       0.54      0.72      0.56       155\nweighted avg       0.98      0.93      0.95       155\n\nSample 5:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.96      0.97       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.95       155\n   macro avg       0.49      0.48      0.49       155\nweighted avg       0.97      0.95      0.96       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.17      0.50      0.25         2\n\n    accuracy                           0.96       155\n   macro avg       0.58      0.73      0.62       155\nweighted avg       0.98      0.96      0.97       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.17      0.50      0.25         2\n\n    accuracy                           0.96       155\n   macro avg       0.58      0.73      0.62       155\nweighted avg       0.98      0.96      0.97       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.88      0.93       153\n           1       0.05      0.50      0.09         2\n\n    accuracy                           0.87       155\n   macro avg       0.52      0.69      0.51       155\nweighted avg       0.98      0.87      0.92       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.87      0.93       153\n           1       0.05      0.50      0.09         2\n\n    accuracy                           0.86       155\n   macro avg       0.52      0.68      0.51       155\nweighted avg       0.98      0.86      0.92       155\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#ADASYN sampling\nfrom imblearn.over_sampling import ADASYN\n\nadasyn = ADASYN(random_state=42)\n\nX_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n\nsample_size = len(X_train) // 5\nsamples = []\nfor i in range(5):\n    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n    X_sample = X_train_resampled.iloc[sample_indices, :]\n    y_sample = y_train_resampled.iloc[sample_indices]\n    samples.append((X_sample, y_sample))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:56:34.847183Z","iopub.execute_input":"2023-02-19T11:56:34.847607Z","iopub.status.idle":"2023-02-19T11:56:34.882508Z","shell.execute_reply.started":"2023-02-19T11:56:34.847571Z","shell.execute_reply":"2023-02-19T11:56:34.881086Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import classification_report\n\nmodels = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\nfor i, (X_sample, y_sample) in enumerate(samples):\n    print(f\"Sample {i+1}:\")\n    for model in models:\n        print(f\"\\t{model.__class__.__name__}:\")\n        model.fit(X_sample, y_sample)\n        y_pred = model.predict(X_test)\n        print(classification_report(y_test, y_pred, zero_division=1))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:57:22.829699Z","iopub.execute_input":"2023-02-19T11:57:22.830120Z","iopub.status.idle":"2023-02-19T11:57:26.902540Z","shell.execute_reply.started":"2023-02-19T11:57:22.830089Z","shell.execute_reply":"2023-02-19T11:57:26.901641Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Sample 1:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.92      0.96       153\n           1       0.08      0.50      0.13         2\n\n    accuracy                           0.92       155\n   macro avg       0.53      0.71      0.54       155\nweighted avg       0.98      0.92      0.95       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.17      0.50      0.25         2\n\n    accuracy                           0.96       155\n   macro avg       0.58      0.73      0.62       155\nweighted avg       0.98      0.96      0.97       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.97       153\n           1       0.10      0.50      0.17         2\n\n    accuracy                           0.94       155\n   macro avg       0.55      0.72      0.57       155\nweighted avg       0.98      0.94      0.96       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.96       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.93       155\n   macro avg       0.49      0.47      0.48       155\nweighted avg       0.97      0.93      0.95       155\n\nSample 2:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.88      0.93       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.87       155\n   macro avg       0.49      0.44      0.47       155\nweighted avg       0.97      0.87      0.92       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.96       155\n   macro avg       0.49      0.49      0.49       155\nweighted avg       0.97      0.96      0.97       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.33      0.50      0.40         2\n\n    accuracy                           0.98       155\n   macro avg       0.66      0.74      0.70       155\nweighted avg       0.98      0.98      0.98       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.97       153\n           1       0.10      0.50      0.17         2\n\n    accuracy                           0.94       155\n   macro avg       0.55      0.72      0.57       155\nweighted avg       0.98      0.94      0.96       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.90      0.94       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.89       155\n   macro avg       0.49      0.45      0.47       155\nweighted avg       0.97      0.89      0.93       155\n\nSample 3:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.95      0.97       153\n           1       0.12      0.50      0.20         2\n\n    accuracy                           0.95       155\n   macro avg       0.56      0.73      0.59       155\nweighted avg       0.98      0.95      0.96       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.33      0.50      0.40         2\n\n    accuracy                           0.98       155\n   macro avg       0.66      0.74      0.70       155\nweighted avg       0.98      0.98      0.98       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       153\n           1       0.33      0.50      0.40         2\n\n    accuracy                           0.98       155\n   macro avg       0.66      0.74      0.70       155\nweighted avg       0.98      0.98      0.98       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.97       153\n           1       0.10      0.50      0.17         2\n\n    accuracy                           0.94       155\n   macro avg       0.55      0.72      0.57       155\nweighted avg       0.98      0.94      0.96       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.96      0.98       153\n           1       0.14      0.50      0.22         2\n\n    accuracy                           0.95       155\n   macro avg       0.57      0.73      0.60       155\nweighted avg       0.98      0.95      0.97       155\n\nSample 4:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.17      0.50      0.25         2\n\n    accuracy                           0.96       155\n   macro avg       0.58      0.73      0.62       155\nweighted avg       0.98      0.96      0.97       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.95      0.97       153\n           1       0.11      0.50      0.18         2\n\n    accuracy                           0.94       155\n   macro avg       0.55      0.72      0.58       155\nweighted avg       0.98      0.94      0.96       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.17      0.50      0.25         2\n\n    accuracy                           0.96       155\n   macro avg       0.58      0.73      0.62       155\nweighted avg       0.98      0.96      0.97       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.89      0.94       153\n           1       0.06      0.50      0.10         2\n\n    accuracy                           0.88       155\n   macro avg       0.52      0.69      0.52       155\nweighted avg       0.98      0.88      0.93       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.92      0.96       153\n           1       0.08      0.50      0.13         2\n\n    accuracy                           0.92       155\n   macro avg       0.53      0.71      0.54       155\nweighted avg       0.98      0.92      0.95       155\n\nSample 5:\n\tAdaBoostClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.93      0.96       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.92       155\n   macro avg       0.49      0.46      0.48       155\nweighted avg       0.97      0.92      0.94       155\n\n\tRandomForestClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.98       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.97       155\n   macro avg       0.49      0.49      0.49       155\nweighted avg       0.97      0.97      0.97       155\n\n\tExtraTreesClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00       153\n           1       1.00      0.50      0.67         2\n\n    accuracy                           0.99       155\n   macro avg       1.00      0.75      0.83       155\nweighted avg       0.99      0.99      0.99       155\n\n\tGradientBoostingClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.95      0.97       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.94       155\n   macro avg       0.49      0.47      0.48       155\nweighted avg       0.97      0.94      0.95       155\n\n\tXGBClassifier:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.96       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.93       155\n   macro avg       0.49      0.47      0.48       155\nweighted avg       0.97      0.93      0.95       155\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from imblearn.ensemble import EasyEnsembleClassifier\nfrom sklearn.metrics import classification_report\n\neec = EasyEnsembleClassifier(n_estimators=10, random_state=42)\n\n# create 5 samples\nsample_size = len(X_train_resampled) // 5\nsamples = []\nfor i in range(5):\n    sample_indices = np.random.choice(len(X_train_resampled), sample_size, replace=True)\n    X_sample = X_train_resampled.iloc[sample_indices, :]\n    y_sample = y_train_resampled.iloc[sample_indices]\n    samples.append((X_sample, y_sample))\n\nfor i, (X_sample, y_sample) in enumerate(samples):\n    print(f\"Sample {i+1}:\")\n    eec.fit(X_sample, y_sample)\n    y_pred = eec.predict(X_test)\n    print(classification_report(y_test, y_pred, zero_division=1))","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:57:54.062786Z","iopub.execute_input":"2023-02-19T11:57:54.063259Z","iopub.status.idle":"2023-02-19T11:58:00.189576Z","shell.execute_reply.started":"2023-02-19T11:57:54.063225Z","shell.execute_reply":"2023-02-19T11:58:00.188317Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Sample 1:\n              precision    recall  f1-score   support\n\n           0       0.99      0.94      0.97       153\n           1       0.10      0.50      0.17         2\n\n    accuracy                           0.94       155\n   macro avg       0.55      0.72      0.57       155\nweighted avg       0.98      0.94      0.96       155\n\nSample 2:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.96       155\n   macro avg       0.49      0.49      0.49       155\nweighted avg       0.97      0.96      0.97       155\n\nSample 3:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.95       155\n   macro avg       0.49      0.48      0.49       155\nweighted avg       0.97      0.95      0.96       155\n\nSample 4:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.00      0.00      0.00         2\n\n    accuracy                           0.96       155\n   macro avg       0.49      0.49      0.49       155\nweighted avg       0.97      0.96      0.97       155\n\nSample 5:\n              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98       153\n           1       0.20      0.50      0.29         2\n\n    accuracy                           0.97       155\n   macro avg       0.60      0.74      0.63       155\nweighted avg       0.98      0.97      0.97       155\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, auc\n\nmodels = [AdaBoostClassifier(), RandomForestClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), XGBClassifier()]\n\nfor i, (X_sample, y_sample) in enumerate(samples):\n    print(f\"Sample {i+1}:\")\n    for model in models:\n        print(f\"\\t{model.__class__.__name__}:\")\n        model.fit(X_sample, y_sample)\n        y_scores = model.predict_proba(X_test)[:, 1]\n        precision, recall, _ = precision_recall_curve(y_test, y_scores)\n        pr_auc = auc(recall, precision)\n        print(f\"\\t\\tPR AUC: {pr_auc:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-19T11:58:22.111613Z","iopub.execute_input":"2023-02-19T11:58:22.112139Z","iopub.status.idle":"2023-02-19T11:58:26.929299Z","shell.execute_reply.started":"2023-02-19T11:58:22.112100Z","shell.execute_reply":"2023-02-19T11:58:26.928235Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Sample 1:\n\tAdaBoostClassifier:\n\t\tPR AUC: 0.089\n\tRandomForestClassifier:\n\t\tPR AUC: 0.505\n\tExtraTreesClassifier:\n\t\tPR AUC: 0.505\n\tGradientBoostingClassifier:\n\t\tPR AUC: 0.089\n\tXGBClassifier:\n\t\tPR AUC: 0.068\nSample 2:\n\tAdaBoostClassifier:\n\t\tPR AUC: 0.011\n\tRandomForestClassifier:\n\t\tPR AUC: 0.041\n\tExtraTreesClassifier:\n\t\tPR AUC: 0.505\n\tGradientBoostingClassifier:\n\t\tPR AUC: 0.017\n\tXGBClassifier:\n\t\tPR AUC: 0.025\nSample 3:\n\tAdaBoostClassifier:\n\t\tPR AUC: 0.041\n\tRandomForestClassifier:\n\t\tPR AUC: 0.508\n\tExtraTreesClassifier:\n\t\tPR AUC: 0.507\n\tGradientBoostingClassifier:\n\t\tPR AUC: 0.055\n\tXGBClassifier:\n\t\tPR AUC: 0.505\nSample 4:\n\tAdaBoostClassifier:\n\t\tPR AUC: 0.014\n\tRandomForestClassifier:\n\t\tPR AUC: 0.130\n\tExtraTreesClassifier:\n\t\tPR AUC: 0.506\n\tGradientBoostingClassifier:\n\t\tPR AUC: 0.042\n\tXGBClassifier:\n\t\tPR AUC: 0.093\nSample 5:\n\tAdaBoostClassifier:\n\t\tPR AUC: 0.090\n\tRandomForestClassifier:\n\t\tPR AUC: 0.505\n\tExtraTreesClassifier:\n\t\tPR AUC: 0.506\n\tGradientBoostingClassifier:\n\t\tPR AUC: 0.505\n\tXGBClassifier:\n\t\tPR AUC: 0.507\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}